<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<meta content="ccsss" name="author"/>
<link href="https://ccss17.github.io/paper/quadruplet/" rel="canonical"/>
<link href="../../assets/images/bolt-solid.svg" rel="icon"/>
<meta content="mkdocs-1.2.2, mkdocs-material-7.2.6" name="generator"/>
<title>Quadruplet (2017) - ccss17</title>
<link href="../../assets/stylesheets/main.802231af.min.css" rel="stylesheet"/>
<link href="../../assets/stylesheets/palette.3f5d1f46.min.css" rel="stylesheet"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css?family=Nanum+Gothic:300,400,400i,700%7C&amp;display=fallback" rel="stylesheet"/>
<style>:root{--md-text-font-family:"Nanum Gothic";--md-code-font-family:""}</style>
<link href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css" rel="stylesheet"/>
<link href="../../stylesheets/config.css" rel="stylesheet"/>
</head>
<body data-md-color-accent="" data-md-color-primary="white" data-md-color-scheme="default" dir="ltr">
<script>function __prefix(e){return new URL("../..",location).pathname+"."+e}function __get(e,t=localStorage){return JSON.parse(t.getItem(__prefix(e)))}</script>
<script>var palette=__get("__palette");if(null!==palette&&"object"==typeof palette.color)for(var key in palette.color)document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
<input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
<input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
<label class="md-overlay" for="__drawer"></label>
<div data-md-component="skip">
<a class="md-skip" href="#quadruplet">
          Skip to content
        </a>
</div>
<div data-md-component="announce">
</div>
<header class="md-header" data-md-component="header">
<nav aria-label="Header" class="md-header__inner md-grid">
<a aria-label="ccss17" class="md-header__button md-logo" data-md-component="logo" href="../.." title="ccss17">
<img alt="logo" src="../../assets/images/bolt-solid.svg"/>
</a>
<label class="md-header__button md-icon" for="__drawer">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"></path></svg>
</label>
<div class="md-header__title" data-md-component="header-title">
<div class="md-header__ellipsis">
<div class="md-header__topic">
<span class="md-ellipsis">
            ccss17
          </span>
</div>
<div class="md-header__topic" data-md-component="header-topic">
<span class="md-ellipsis">
            
              Quadruplet (2017)
            
          </span>
</div>
</div>
</div>
<form class="md-header__option" data-md-component="palette">
<input aria-label="Switch to dark mode" class="md-option" data-md-color-accent="" data-md-color-media="" data-md-color-primary="white" data-md-color-scheme="default" id="__palette_1" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_2" hidden="" title="Switch to dark mode">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 2a7 7 0 0 1 7 7c0 2.38-1.19 4.47-3 5.74V17a1 1 0 0 1-1 1H9a1 1 0 0 1-1-1v-2.26C6.19 13.47 5 11.38 5 9a7 7 0 0 1 7-7M9 21v-1h6v1a1 1 0 0 1-1 1h-4a1 1 0 0 1-1-1m3-17a5 5 0 0 0-5 5c0 2.05 1.23 3.81 3 4.58V16h4v-2.42c1.77-.77 3-2.53 3-4.58a5 5 0 0 0-5-5z"></path></svg>
</label>
<input aria-label="Switch to light mode" class="md-option" data-md-color-accent="" data-md-color-media="" data-md-color-primary="deep-purple" data-md-color-scheme="slate" id="__palette_2" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_1" hidden="" title="Switch to light mode">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 2a7 7 0 0 0-7 7c0 2.38 1.19 4.47 3 5.74V17a1 1 0 0 0 1 1h6a1 1 0 0 0 1-1v-2.26c1.81-1.27 3-3.36 3-5.74a7 7 0 0 0-7-7M9 21a1 1 0 0 0 1 1h4a1 1 0 0 0 1-1v-1H9v1z"></path></svg>
</label>
</form>
</nav>
</header>
<div class="md-container" data-md-component="container">
<nav aria-label="Tabs" class="md-tabs" data-md-component="tabs">
<div class="md-tabs__inner md-grid">
<ul class="md-tabs__list">
<li class="md-tabs__item">
<a class="md-tabs__link" href="../..">
      ccss17
    </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../Math/MathHistory/">
        Math
      </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link md-tabs__link--active" href="../1404.6388/">
        Paper
      </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../Computer/nand2tetris/">
        Computer
      </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../ProgrammerBase/">
        ProgrammerBase
      </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../security-tutorial/">
        security tutorial
      </a>
</li>
</ul>
</div>
</nav>
<main class="md-main" data-md-component="main">
<div class="md-main__inner md-grid">
<div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Navigation" class="md-nav md-nav--primary md-nav--lifted" data-md-level="0">
<label class="md-nav__title" for="__drawer">
<a aria-label="ccss17" class="md-nav__button md-logo" data-md-component="logo" href="../.." title="ccss17">
<img alt="logo" src="../../assets/images/bolt-solid.svg"/>
</a>
    ccss17
  </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../..">
        ccss17
      </a>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" id="__nav_2" type="checkbox"/>
<label class="md-nav__link" for="__nav_2">
        Math
        <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="Math" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_2">
<span class="md-nav__icon md-icon"></span>
          Math
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2_1" id="__nav_2_1" type="checkbox"/>
<label class="md-nav__link" for="__nav_2_1">
        Foundation of Math
        <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="Foundation of Math" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_2_1">
<span class="md-nav__icon md-icon"></span>
          Foundation of Math
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../Math/MathHistory/">
        History of Math
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../Math/Logic/FormalSystem/">
        Formal System
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../Math/incompleteness/">
        Incompleteness theorem
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../Math/turing/">
        Turing's proof
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../Math/gentzen/">
        Consistency proof of Peano arithmetic
      </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2_2" id="__nav_2_2" type="checkbox"/>
<label class="md-nav__link" for="__nav_2_2">
        Set Theory
        <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="Set Theory" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_2_2">
<span class="md-nav__icon md-icon"></span>
          Set Theory
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../Math/Set/Set/">
        Set
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../Math/Set/numbers/">
        Number Theory
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../Math/Set/InfiniteSet/">
        Infinite Set
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../Math/Set/ZFC/">
        ZFC axiom system
      </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../Math/ArithmeticOperations/">
        Arithmetic Operations
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../Math/Polynomials/">
        Polynomials
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../Math/HyperrealNumbers/">
        Hyperreal Numbers
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../Math/SurrealNumbers/">
        Surreal Numbers
      </a>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2_7" id="__nav_2_7" type="checkbox"/>
<label class="md-nav__link" for="__nav_2_7">
        Linear Algebra
        <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="Linear Algebra" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_2_7">
<span class="md-nav__icon md-icon"></span>
          Linear Algebra
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../Math/LinearAlgebra/VectorSpace/">
        Vector Space
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../Math/LinearAlgebra/LinearTransformation/">
        Linear Transformation
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../Math/LinearAlgebra/MatrixOperation/">
        Matrix Operation
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../Math/LinearAlgebra/Determinants/">
        Determinants
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../Math/LinearAlgebra/Diagonalization/">
        Diagonalization
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../Math/LinearAlgebra/InnerProductSpaces/">
        Inner Product Spaces
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../Math/LinearAlgebra/CanonicalForms/">
        Canonical Forms
      </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" id="__nav_3" type="checkbox"/>
<label class="md-nav__link" for="__nav_3">
        Paper
        <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="Paper" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_3">
<span class="md-nav__icon md-icon"></span>
          Paper
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../1404.6388/">
        Performance of Python runtimes on a non-numeric scientific code
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../1102.1523/">
        The NumPy array: a structure for efficient numerical computation
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../facenet/">
        Facenet (2015)
      </a>
</li>
<li class="md-nav__item md-nav__item--active">
<input class="md-nav__toggle md-toggle" data-md-toggle="toc" id="__toc" type="checkbox"/>
<label class="md-nav__link md-nav__link--active" for="__toc">
          Quadruplet (2017)
          <span class="md-nav__icon md-icon"></span>
</label>
<a class="md-nav__link md-nav__link--active" href="./">
        Quadruplet (2017)
      </a>
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
<!-- <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label> -->
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#quadruplet">
    Quadruplet 사전지식
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#translation-beyond-triplet-loss-one-shot-learning-experiments-with-quadruplet-loss-by-eric-craeymeersch">
    (Translation) Beyond triplet loss : One shot learning experiments with quadruplet loss (by Eric Craeymeersch)
  </a>
<nav aria-label="(Translation) Beyond triplet loss : One shot learning experiments with quadruplet loss (by Eric Craeymeersch)" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#the-quadloss-paper">
    The "QuadLoss" paper
  </a>
<nav aria-label="The " class="md-nav" paper="" quadloss="">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#triplet-loss">
    triplet loss 함수 개선
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#learned-metric">
    Learned metric
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#training-architecture">
    Training architecture
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#mining-strategy">
    Mining strategy
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#extensive-loss-functions-study">
    Extensive loss functions study
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#our-challenge">
    Our Challenge
  </a>
<nav aria-label="Our Challenge" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#_1">
    데이터셋 준비
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#mining-strategy_1">
    Mining Strategy
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#keras">
    Keras 로 모델 만들기
  </a>
<nav aria-label="Keras 로 모델 만들기" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#the-encoder">
    The encoder
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#the-learned-metric">
    The learned metric
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#loss-functions">
    Loss functions
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#assembling-our-keras-models">
    Assembling our Keras models
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_2">
    실제 학습하기
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#discussion">
    Discussion
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#summary">
    Summary
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#beyond-triplet-loss-a-deep-quadruplet-network-for-person-re-identification">
    《Beyond triplet loss: a deep quadruplet network for person re-identification》
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#abstract">
    Abstract
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#1-introduction">
    1. Introduction
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#2-related-work">
    2. Related work
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#3-the-proposed-approachd">
    3. The proposed approachd
  </a>
<nav aria-label="3. The proposed approachd" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#31-the-triplet-loss">
    3.1. The triplet loss
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#32-the-quadruplet-loss">
    3.2. The quadruplet loss
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#33-margin-based-online-hard-negative-mining">
    3.3. Margin-based online hard negative mining
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#4-relationships-of-different-losses">
    4. Relationships of different losses
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#5-experiment">
    5. Experiment
  </a>
<nav aria-label="5. Experiment" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#51-implementation-and-datasets">
    5.1. Implementation and Datasets
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#52-results-of-quadruplet-network">
    5.2. Results of Quadruplet Network
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#53-comparison-with-the-state-of-the-arts">
    5.3. Comparison with the state of the arts
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#6-conclusion">
    6. Conclusion
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../blueborne/">
        BlueBorne
      </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" id="__nav_4" type="checkbox"/>
<label class="md-nav__link" for="__nav_4">
        Computer
        <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="Computer" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_4">
<span class="md-nav__icon md-icon"></span>
          Computer
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../Computer/nand2tetris/">
        Nand to Tetris
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../Computer/future/">
        Why the future doesn't need us
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../Computer/Rust/">
        Rust Memo
      </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5" id="__nav_5" type="checkbox"/>
<label class="md-nav__link" for="__nav_5">
        ProgrammerBase
        <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="ProgrammerBase" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_5">
<span class="md-nav__icon md-icon"></span>
          ProgrammerBase
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../ProgrammerBase/">
        README
      </a>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5_2" id="__nav_5_2" type="checkbox"/>
<label class="md-nav__link" for="__nav_5_2">
        Contents
        <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="Contents" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_5_2">
<span class="md-nav__icon md-icon"></span>
          Contents
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../ProgrammerBase/01-Day1/readme/">
        Day 1
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../ProgrammerBase/02-Day2/readme/">
        Day 2
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../ProgrammerBase/03-Day3/readme/">
        Day 3
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../ProgrammerBase/04-Day4/readme/">
        Day 4
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../ProgrammerBase/05-Day5/readme/">
        Day 5
      </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../ProgrammerBase/docker/">
        Docker
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../ProgrammerBase/codingconvention/">
        Coding Convention
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../ProgrammerBase/build/">
        Build System
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../ProgrammerBase/information/">
        Information
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../ProgrammerBase/git/">
        Git
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../ProgrammerBase/vscode/">
        VSCode
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../ProgrammerBase/markdown/">
        Markdown
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../ProgrammerBase/tmux/">
        Tmux
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../ProgrammerBase/vim/">
        Vim
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../ProgrammerBase/cli/">
        CLI
      </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6" id="__nav_6" type="checkbox"/>
<label class="md-nav__link" for="__nav_6">
        security tutorial
        <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="security tutorial" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_6">
<span class="md-nav__icon md-icon"></span>
          security tutorial
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../security-tutorial/">
        README
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../security-tutorial/01-Base/">
        Day1 Base
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../security-tutorial/02-Computer1/">
        Day2 Computer Principle 1
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../security-tutorial/03-Computer2/">
        Day3 Computer Principle 2
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../security-tutorial/04-Reversing1/">
        Day4 Reversing 1
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../security-tutorial/05-Reversing2/">
        Day5 Reversing 2
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../security-tutorial/06-Exploit1/">
        Day6 Exploit 1
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../security-tutorial/07-Exploit2/">
        Day7 Exploit 2
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../security-tutorial/08-Exploit3/">
        Day8 Exploit 3
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../security-tutorial/09-Exploit4/">
        Day9 Exploit 4
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../security-tutorial/10-Pentesting/">
        Day10 Pentesting
      </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
<!-- <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label> -->
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#quadruplet">
    Quadruplet 사전지식
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#translation-beyond-triplet-loss-one-shot-learning-experiments-with-quadruplet-loss-by-eric-craeymeersch">
    (Translation) Beyond triplet loss : One shot learning experiments with quadruplet loss (by Eric Craeymeersch)
  </a>
<nav aria-label="(Translation) Beyond triplet loss : One shot learning experiments with quadruplet loss (by Eric Craeymeersch)" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#the-quadloss-paper">
    The "QuadLoss" paper
  </a>
<nav aria-label="The " class="md-nav" paper="" quadloss="">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#triplet-loss">
    triplet loss 함수 개선
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#learned-metric">
    Learned metric
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#training-architecture">
    Training architecture
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#mining-strategy">
    Mining strategy
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#extensive-loss-functions-study">
    Extensive loss functions study
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#our-challenge">
    Our Challenge
  </a>
<nav aria-label="Our Challenge" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#_1">
    데이터셋 준비
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#mining-strategy_1">
    Mining Strategy
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#keras">
    Keras 로 모델 만들기
  </a>
<nav aria-label="Keras 로 모델 만들기" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#the-encoder">
    The encoder
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#the-learned-metric">
    The learned metric
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#loss-functions">
    Loss functions
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#assembling-our-keras-models">
    Assembling our Keras models
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_2">
    실제 학습하기
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#discussion">
    Discussion
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#summary">
    Summary
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#beyond-triplet-loss-a-deep-quadruplet-network-for-person-re-identification">
    《Beyond triplet loss: a deep quadruplet network for person re-identification》
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#abstract">
    Abstract
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#1-introduction">
    1. Introduction
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#2-related-work">
    2. Related work
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#3-the-proposed-approachd">
    3. The proposed approachd
  </a>
<nav aria-label="3. The proposed approachd" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#31-the-triplet-loss">
    3.1. The triplet loss
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#32-the-quadruplet-loss">
    3.2. The quadruplet loss
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#33-margin-based-online-hard-negative-mining">
    3.3. Margin-based online hard negative mining
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#4-relationships-of-different-losses">
    4. Relationships of different losses
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#5-experiment">
    5. Experiment
  </a>
<nav aria-label="5. Experiment" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#51-implementation-and-datasets">
    5.1. Implementation and Datasets
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#52-results-of-quadruplet-network">
    5.2. Results of Quadruplet Network
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#53-comparison-with-the-state-of-the-arts">
    5.3. Comparison with the state of the arts
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#6-conclusion">
    6. Conclusion
  </a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-content" data-md-component="content">
<article class="md-content__inner md-typeset">
<h1>Quadruplet (2017)</h1>
<h2 id="quadruplet">Quadruplet 사전지식<a class="headerlink" href="#quadruplet" title="Permanent link">¶</a></h2>
<h2 id="translation-beyond-triplet-loss-one-shot-learning-experiments-with-quadruplet-loss-by-eric-craeymeersch">(Translation) Beyond triplet loss : One shot learning experiments with quadruplet loss (by Eric Craeymeersch)<a class="headerlink" href="#translation-beyond-triplet-loss-one-shot-learning-experiments-with-quadruplet-loss-by-eric-craeymeersch" title="Permanent link">¶</a></h2>
<dl>
<dt><em>References</em>: </dt>
<dd>
<p><a href="https://medium.com/@crimy/beyond-triplet-loss-one-shot-learning-experiments-with-quadruplet-loss-16671ed51290">https://medium.com/@crimy/beyond-triplet-loss-one-shot-learning-experiments-with-quadruplet-loss-16671ed51290</a></p>
</dd>
</dl>
<h3 id="the-quadloss-paper">The "QuadLoss" paper<a class="headerlink" href="#the-quadloss-paper" title="Permanent link">¶</a></h3>
<p>이 논문은 <strong>FaceNet</strong> 이후 2년 후에 나온 논문으로써 서로 다른 감시 카메라가 한 사람을 추적하는 관점에서의 재식별(re-identification) 을 연구한다. 가령 카메라 1 로 어떤 사람을 추적하다가, 카메라 2 가 같은 사람을 찍었을 때 똑같은 사람인지 어떻게 인식하게 할 것인가? 이 문제는 두 카메라가 다른 포즈, 다른 각도, 다른 명조로 동일 인물을 촬영하므로 생각보다 어려운 문제다.</p>
<p>이 논문은 4 파트로 요약된다.</p>
<ul>
<li>
<p>triplet loss 함수 개선</p>
</li>
<li>
<p>Learned metric</p>
</li>
<li>
<p>Mining strategy</p>
</li>
<li>
<p>Extensive loss functions study</p>
</li>
</ul>
<h4 id="triplet-loss">triplet loss 함수 개선<a class="headerlink" href="#triplet-loss" title="Permanent link">¶</a></h4>
<p>원래 triplet loss 함수는 다음과 같았다. <span class="arithmatex">\([z] _{+} = \max (z, 0)\)</span> 와 입력 이미지 <span class="arithmatex">\(f(x_i), f(x_j), f(x_k)\)</span> 와 하이퍼파라미터 <span class="arithmatex">\(\alpha _{trp}\)</span> 에 대하여</p>
<div class="arithmatex">\[ L _{trp} = \sum_{i,j,k}^{N} [\|f(x_i) - f(x_j)\| ^{2} _{2} - \|f(x_i) - f(x_k)\|^{2}_{2} + \alpha _{trp}]_{+} \tag{1} \]</div>
<p>이때 <span class="arithmatex">\(x_i\)</span> 가 anchor, <span class="arithmatex">\(x_j\)</span> 가 positive, <span class="arithmatex">\(x_k\)</span> 가 negative 를 뜻한다. 하지만 이 논문에서는 anchor 라는 단어를 사용하지 않고 reference 혹은 ref 를 사용한다. 논문에서는 이 함수를 다음과 같이 개선한다. learned metric 을 사용하는 <span class="arithmatex">\(f(x_i) - f(x_j)\)</span> 인 <span class="arithmatex">\(g(x_i, x_j)\)</span> 에 대하여 </p>
<p><img alt="image" src="https://user-images.githubusercontent.com/16812446/96069879-14d38d00-0eda-11eb-913b-b650cd8fd981.png"/></p>
<p>이 손실함수는 triplet loss 함수와 동일하게 Anchor-Positive 거리와 Anchor-Negative 거리의 차이값을 포함하지만, 단지 Anchor-Positive 거리와 Negative-AnotherNegative 거리의 차이값도 계산하고 있다. 이에 따라 새로운 하이퍼파라미터 <span class="arithmatex">\(\alpha _{2}\)</span> 가 추가되었다. AnotherNegative 란 기존의 negative 와 다른 클래스에서 가져온 negative 샘플이다.</p>
<dl>
<dt>그러므로 이것을 계산하기 위하여 Anchor(A), Positive(P), Negative(N), Negative2(N2) 가 필요하다. 이제 Anchor 와 Positive 의 거리를 AP 라고 하고 Negative 와 Negative2 의 거리를 NN 이라고 하자. 그러면 triplet loss 와 quadruplet loss 를 단순하게 다음과 같이 쓸 수 있다.</dt>
<dd>
<p>Triplet loss = AP - AN + alpha1</p>
</dd>
<dd>
<p>Quadruplet loss = AP - AN + alpha1 + AP - NN + alpha2</p>
</dd>
<dt>이 논문은 위 수식의 항들을 편의상 다음과 같이 부른다.</dt>
<dd>
<p>"AP - AN + alpha1" 를 "strong" push (alpha1 = 1) 라고 부른다.</p>
</dd>
<dd>
<p>"AP - NN + alpha2" 를 "weak" push (alpha1 &lt; 0.5) 라고 부른다.</p>
</dd>
</dl>
<h4 id="learned-metric">Learned metric<a class="headerlink" href="#learned-metric" title="Permanent link">¶</a></h4>
<p>원래의 손실함수에서는 거리를 계산할 때 L2 거리</p>
<div class="arithmatex">\[ \text{L2dist} (a, b) = (a - b) ^{2} \]</div>
<p>로 계산했다. 하지만 이 논문에서는 L2 거리를 neural network 로 대체했다. learned metrics 에 대한 자료는 매우 많으므로 생략하겠다.</p>
<h4 id="training-architecture">Training architecture<a class="headerlink" href="#training-architecture" title="Permanent link">¶</a></h4>
<dl>
<dt><img alt="" src="https://miro.medium.com/max/1313/1*9QVFD-io7Ods-o9CFL9gMw.png"/></dt>
<dd>
<p>논문에서 설명된 학습 구조. 분홍생 파트가 FaceNet 구조에서 새롭게 추가된 파트이다.</p>
</dd>
</dl>
<p>학습 구조는 세 파트로 진행된다.</p>
<ul>
<li>
<p>첫번째 파트는 4가지 이미지를 받아서 동일한 conv 계층을 통해 벡터로 변환한다. </p>
</li>
<li>
<p>그런 다음 벡터를 AP(ref-pos), AN(ref-neg), NN(neg-neg2) 로 그룹화한다. </p>
</li>
<li>
<p>그리고 기존에 이 페어의 L2 거리를 계산하는 것과 다르게 learned metric network 로 보낸다. 그리고 최종적으로 binary softmax 로 보내서 같은 사람인지, 다른 사람인지 두 가지 값만을 출력하게 한다. 후자의 값만이 거리 표시기 또는 비유사도 표시기로 작동한다.</p>
</li>
<li>
<p>마지막으로 3 개의 softmax 로 손실 함수를 계산한다.</p>
</li>
</ul>
<h4 id="mining-strategy">Mining strategy<a class="headerlink" href="#mining-strategy" title="Permanent link">¶</a></h4>
<p>마이닝은 말 그대로 학습할 샘플을 선택하는 것이다. 우리는 샘플이 얼마나 hard 하냐는 것을 샘플이 생성하는 손실값이 얼마나 되느냐로 말할 것이다.</p>
<ul>
<li>
<p>easy 샘플이란 손실값이 작거나 없는 것이다. 가령 anchor 와 매우 가까운 positive 이거나 anchor 와 매우 먼 negative 가 easy sample 이라고 할 수 있다.</p>
</li>
<li>
<p>hard 샘플이란 손실값을 매우 크게 배출하는 샘플이다. 가령 anchor 와 매우 먼 positive 이거나 anchor 와 매우 가까운 negative 가 easy sample 이라고 할 수 있다.</p>
</li>
<li>
<p>이 중간에, 마진을 뜻하는 alpha1 과 alpha2 의 경계에 있는 semi-hard 샘플이 존재한다.</p>
</li>
</ul>
<p>easy 샘플을 선택해서 학습하는 건 전체 시스템에 별 도움이 안된다. <strong>따라서 마이닝이란 hard 샘플 혹은 semi-hard 샘플을 빠르게 찾아서 시스템의 학습이 빠르게 진행될 수 있도록 하는 것이다.</strong> </p>
<p>이 논문은 배치에서 선택될 hard 샘플을 가려내는 dynamic threshold 를 기반으로 하는 aggressive mining strategy 를 소개한다. 이것에 관해서 여기에서는 자세히 설명하지 않을 것이다.</p>
<h4 id="extensive-loss-functions-study">Extensive loss functions study<a class="headerlink" href="#extensive-loss-functions-study" title="Permanent link">¶</a></h4>
<p>그러고나서 이 논문은 다른 종류의 손실함수의 차이점에 대하여 분석한다. 만약 이 주제에 대하여 더 알고 싶고, 아카데믹한 설명을 이해하는데에 거부감이 없다면 이 파트도 읽어보길 바란다.</p>
<h3 id="our-challenge">Our Challenge<a class="headerlink" href="#our-challenge" title="Permanent link">¶</a></h3>
<p>이 포스트에서 우리는 두 이미지가 서로 기호를 뜻하는지 같은 기호를 뜻하는지 One shot learning system 으로 판별해볼 것이다. OMNIGLOT 데이터셋을 사용할 건데, 이 데이터셋은 50 개의 다른 알파벳에서 온 1623 개의 손글씨 문자를 갖고 있다. MNIST 가 10 개의 클래스에 클래스 당 6000 개의 샘플을 갖고 있는 것과 달리 우리는 1623 클래스와 클래스 당 20 개의 샘플을 갖고 있는 이 데이터셋을 사용할 것이다.</p>
<dl>
<dt><img alt="" src="https://miro.medium.com/max/1313/1*FhHGYU4S5xnW5s5rl3JcEA.jpeg"/></dt>
<dd>
<p>omnigplot 데이터셋 </p>
</dd>
</dl>
<p>이 데이터셋을 964 개의 훈련용 클래스와 659 개의 시험용 클래스로 분할할 수 있다. 이는 시험용 데이터셋에 샘플들만 있는 것이 아니라 훈련 때 사용되지 않은 전혀 새로운 클래스도 포함되어 있다는 것이다. 이것이 MNIST 와 가장 다른 차이점이다. </p>
<p>우리는 기존의 triplet loss 를 사용해서 학습을 해보고, quadruplet loss 사용해서 학습을 해볼 것이다. 그리고 이 두 시스템을 다음과 같이 최대한 동일한 환경으로 학습시켜볼 것이다. </p>
<ul>
<li>
<p>동일한 데이터를 동일한 시간으로 동일한 에폭으로 동일한 mining strategy 로 학습시킨다.</p>
</li>
<li>
<p>인코더(사진을 벡터로 변환하는 계층) 파트를 동일한 neural network 구조를 사용할 것이다. 두 인코더가 완전히 똑같은 파라미터와 동일한 크기(여기에서는 20)를 갖도록 할 것이다.</p>
</li>
</ul>
<p>하지만 quadruplet 시스템에는 다음의 기능을 추가하게 된다.</p>
<ul>
<li>
<p>quadruplet loss 함수에는 dist(A, P)-dist(N, N2) 가 더해진다.</p>
</li>
<li>
<p>L2 거리 대신 learned metric 을 사용한다. 이것은 모델에 또 다른 neural network 를 더함으로써 이루어진다.</p>
</li>
</ul>
<p>즉, triplet loss 시스템(3x) 과 quadruplet loss + learned metric system(4x) 을 비교해보는 것이다.</p>
<h4 id="_1">데이터셋 준비<a class="headerlink" href="#_1" title="Permanent link">¶</a></h4>
<p>먼저 OMNIGLOT 을 다운로드 받아서 그레이스케일로 변환하고, <span class="arithmatex">\(0-255\)</span> 의 값을 <span class="arithmatex">\(0-1\)</span> 로 정규화한다. 그러고나서 데이터셋을 다음의 자료구조로 저장한다.</p>
<ul>
<li>
<p>X 에 모든 이미지를 저장한다. Y 에 true labels (class 번호들) 을 저장한다. </p>
</li>
<li>
<p>dataset_train 이라는 자료구조를 정의한다. 가령 dataset_train[0] 에는 모든 class 0 을 갖는 이미지 (?, 105, 105, 1) 들이 저장되어 있다. 이렇게 하면 나중에 특정 클래스에 대한 샘플링(quadruplet (A, P, N, N2) 를 만드는 것)을 할 때 편하다.</p>
</li>
</ul>
<h4 id="mining-strategy_1">Mining Strategy<a class="headerlink" href="#mining-strategy_1" title="Permanent link">¶</a></h4>
<p>4x 에 대한 mining strategy 는 단순하게 할 것이다.</p>
<ul>
<li>
<p>100 개의 quadruplet 을 한 배치로 만든다.</p>
</li>
<li>
<p>16 개의 hardest quadruplet 을 택한다. </p>
</li>
<li>
<p>16 개의 랜덤 quadruplet 을 택하여 32 개의 샘플을 만든다.</p>
</li>
</ul>
<dl>
<dt><img alt="" src="https://miro.medium.com/max/1313/1*_Ar5aeP-dPgXwNoWznddeQ.png"/></dt>
<dd>
<p>hard quadruplet 예시</p>
</dd>
</dl>
<p>3x 는 triplet 을 사용하기 때문에 다음과 같다.</p>
<ul>
<li>
<p>4x 에서 준비한 100 개의 quadruplet 에서 APN 를 구성하기 위한 첫 3 개의 이미지들을 추출하여 100 개의 triplet 을 한 배치로 만든다. </p>
</li>
<li>
<p>16 개의 hardest triplet 을 선택한다. </p>
</li>
<li>
<p>16 개의 무작위 triplet 을 선택하여 32 개의 샘플로 이루어진 배치를 만든다. </p>
</li>
</ul>
<dl>
<dt><img alt="" src="https://miro.medium.com/max/1313/1*w15NaxvjlIx81hdtqIFkZw.png"/></dt>
<dd>
<p>hard triplet 예시 </p>
</dd>
</dl>
<h3 id="keras">Keras 로 모델 만들기<a class="headerlink" href="#keras" title="Permanent link">¶</a></h3>
<h4 id="the-encoder">The encoder<a class="headerlink" href="#the-encoder" title="Permanent link">¶</a></h4>
<p>논문에서는 pretrained Resnet 을 사용했지만, 여기에서는 그것이 유용하지 않으니 (conv/pool) * 3 + fc 조합을 사용하겠다. 마지막 계층은 embedding 값이 full range 를 갖도록 하기 위하여 어떤 활성화함수도 가지면 안된다.</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">build_network</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,</span> <span class="n">embeddingsize</span><span class="p">):</span>
    <span class="sd">'''</span>
<span class="sd">    Define the neural network to learn image similarity</span>
<span class="sd">    Input : </span>
<span class="sd">            input_shape : shape of input images</span>
<span class="sd">            embeddingsize : vectorsize used to encode our picture   </span>
<span class="sd">    '''</span>
    <span class="c1"># Convolutional Neural Network</span>
    <span class="n">network</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
    <span class="n">network</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">7</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">,</span><span class="n">padding</span><span class="o">=</span><span class="s1">'same'</span><span class="p">,</span>
                     <span class="n">input_shape</span><span class="o">=</span><span class="n">input_shape</span><span class="p">,</span>
                     <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">'he_uniform'</span><span class="p">,</span>
                     <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">l2</span><span class="p">(</span><span class="mf">2e-4</span><span class="p">)))</span>
    <span class="n">network</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPooling2D</span><span class="p">())</span>
    <span class="n">network</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">'he_uniform'</span><span class="p">,</span><span class="n">padding</span><span class="o">=</span><span class="s1">'same'</span><span class="p">,</span>
                     <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">l2</span><span class="p">(</span><span class="mf">2e-4</span><span class="p">)))</span>
    <span class="n">network</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPooling2D</span><span class="p">())</span>
    <span class="n">network</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">'he_uniform'</span><span class="p">,</span><span class="n">padding</span><span class="o">=</span><span class="s1">'same'</span><span class="p">,</span>
                     <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">l2</span><span class="p">(</span><span class="mf">2e-4</span><span class="p">)))</span>
    <span class="n">network</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Flatten</span><span class="p">())</span>
    <span class="n">network</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">2048</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">,</span>
                   <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">l2</span><span class="p">(</span><span class="mf">1e-3</span><span class="p">),</span>
                   <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">'he_uniform'</span><span class="p">))</span>
    <span class="n">network</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">embeddingsize</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                   <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">l2</span><span class="p">(</span><span class="mf">1e-3</span><span class="p">),</span>
                   <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">'he_uniform'</span><span class="p">))</span>
    <span class="c1">#Force the encoding to live on the d-dimentional hypershpere</span>
    <span class="n">network</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">K</span><span class="o">.</span><span class="n">l2_normalize</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)))</span>
    <span class="k">return</span> <span class="n">network</span>
</code></pre></div>
<h4 id="the-learned-metric">The learned metric<a class="headerlink" href="#the-learned-metric" title="Permanent link">¶</a></h4>
<p>4x 시스템을 위해서 두 embedding 을 받아서 거리를 출력해주는 neural network 를 만들어야 한다. 우리는 3 개의 fc 와 논문에서와 같이 binary softmax 를 사용할 것이다. 우리는 두 embedding 이 유사하지 않은 확률을 뜻하는 거리를 표현하는 숫자 하나만 필요하기 때문에 softmax 의 출력 하나만을 취할 것이다. </p>
<p>이때 두 embedding 을 연결하여 첫번째 계층에 입력할 것이다.</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">build_metric_network</span><span class="p">(</span><span class="n">single_embedding_shape</span><span class="p">):</span>
    <span class="sd">'''</span>
<span class="sd">    Define the neural network to learn the metric</span>
<span class="sd">    Input : </span>
<span class="sd">            single_embedding_shape : shape of input embeddings or feature map. Must be an array</span>
<span class="sd">    '''</span>
    <span class="c1">#compute shape for input</span>
    <span class="n">input_shape</span> <span class="o">=</span> <span class="n">single_embedding_shape</span>
    <span class="c1">#the two input embeddings will be concatenated    </span>
    <span class="n">input_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">input_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="mi">2</span>
     <span class="c1"># Neural Network</span>
    <span class="n">network</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">"learned_metric"</span><span class="p">)</span>
    <span class="n">network</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">,</span>
                   <span class="n">input_shape</span><span class="o">=</span><span class="n">input_shape</span><span class="p">,</span> 
                   <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">l2</span><span class="p">(</span><span class="mf">1e-3</span><span class="p">),</span>
                   <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">'he_uniform'</span><span class="p">))</span>
    <span class="n">network</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">,</span>                   
                   <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">l2</span><span class="p">(</span><span class="mf">1e-3</span><span class="p">),</span>
                   <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">'he_uniform'</span><span class="p">))</span>  
    <span class="n">network</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">,</span>                   
                   <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">l2</span><span class="p">(</span><span class="mf">1e-3</span><span class="p">),</span>
                   <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">'he_uniform'</span><span class="p">))</span>
    <span class="c1">#Last layer : binary softmax</span>
    <span class="n">network</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'softmax'</span><span class="p">))</span>
    <span class="c1">#Select only one output value from the softmax</span>
    <span class="n">network</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]))</span>
    <span class="k">return</span> <span class="n">network</span>
</code></pre></div>
<h4 id="loss-functions">Loss functions<a class="headerlink" href="#loss-functions" title="Permanent link">¶</a></h4>
<p>3x 시스템을 위해서 A, P, N 을 입력받아서 triplet loss 함수 정의대로 L2 거리를 계산하고 모두 더하는 클래스를 정의해준다. </p>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">TripletLossLayer</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TripletLossLayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">triplet_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="n">anchor</span><span class="p">,</span> <span class="n">positive</span><span class="p">,</span> <span class="n">negative</span> <span class="o">=</span> <span class="n">inputs</span>
        <span class="n">p_dist</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">anchor</span><span class="o">-</span><span class="n">positive</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">n_dist</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">anchor</span><span class="o">-</span><span class="n">negative</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">K</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">p_dist</span> <span class="o">-</span> <span class="n">n_dist</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">triplet_loss</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add_loss</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>
</code></pre></div>
<p>4x 시스템을 위해서 learned metric 으로 이미 학습된 AP, AN, NN 을 입력받아서 마찬가지로 quadruplet loss 함수 정의대로 계산해준다.</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">QuadrupletLossLayer</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">beta</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">debugeric</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">QuadrupletLossLayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">quadruplet_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="n">ap_dist</span><span class="p">,</span><span class="n">an_dist</span><span class="p">,</span><span class="n">nn_dist</span> <span class="o">=</span> <span class="n">inputs</span>
        <span class="n">ap_dist2</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">ap_dist</span><span class="p">)</span>
        <span class="n">an_dist2</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">an_dist</span><span class="p">)</span>
        <span class="n">nn_dist2</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">nn_dist</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">K</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">ap_dist2</span> <span class="o">-</span> <span class="n">an_dist2</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="n">K</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">ap_dist2</span> <span class="o">-</span> <span class="n">nn_dist2</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">quadruplet_loss</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add_loss</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>
</code></pre></div>
<h4 id="assembling-our-keras-models">Assembling our Keras models<a class="headerlink" href="#assembling-our-keras-models" title="Permanent link">¶</a></h4>
<p>이제 3x 시스템 전체를 만들 수 있다.</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">build_model3</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,</span> <span class="n">network</span><span class="p">,</span> <span class="n">margin</span><span class="o">=</span><span class="mf">0.2</span><span class="p">):</span>
    <span class="sd">'''</span>
<span class="sd">    Define the Keras Model for training </span>
<span class="sd">        Input : </span>
<span class="sd">            input_shape : shape of input images</span>
<span class="sd">            network : Neural network to train outputing embeddings</span>
<span class="sd">            margin : minimal distance between Anchor-Positive and Anchor-Negative for the lossfunction (alpha)</span>

<span class="sd">    '''</span>
     <span class="c1"># Define the tensors for the three input images</span>
    <span class="n">anchor_input</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">"anchor_input"</span><span class="p">)</span>
    <span class="n">positive_input</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">"positive_input"</span><span class="p">)</span>
    <span class="n">negative_input</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">"negative_input"</span><span class="p">)</span> 
    <span class="c1"># Generate the encodings (feature vectors) for the three images</span>
    <span class="n">encoded_a</span> <span class="o">=</span> <span class="n">network</span><span class="p">(</span><span class="n">anchor_input</span><span class="p">)</span>
    <span class="n">encoded_p</span> <span class="o">=</span> <span class="n">network</span><span class="p">(</span><span class="n">positive_input</span><span class="p">)</span>
    <span class="n">encoded_n</span> <span class="o">=</span> <span class="n">network</span><span class="p">(</span><span class="n">negative_input</span><span class="p">)</span>
    <span class="c1">#TripletLoss Layer</span>
    <span class="n">loss_layer</span> <span class="o">=</span> <span class="n">TripletLossLayer</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="n">margin</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s1">'3xLoss'</span><span class="p">)([</span><span class="n">encoded_a</span><span class="p">,</span><span class="n">encoded_p</span><span class="p">,</span><span class="n">encoded_n</span><span class="p">])</span>
    <span class="c1"># Connect the inputs with the outputs</span>
    <span class="n">network_train</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">anchor_input</span><span class="p">,</span><span class="n">positive_input</span><span class="p">,</span><span class="n">negative_input</span><span class="p">],</span><span class="n">outputs</span><span class="o">=</span><span class="n">loss_layer</span><span class="p">)</span>
    <span class="c1"># return the model</span>
    <span class="k">return</span> <span class="n">network_train</span>
</code></pre></div>
<p><img alt="" src="https://miro.medium.com/max/1313/1*VpRE32TwrTM3nfGAuXuoBw.png"/></p>
<p>또 4x 전체 시스템도 AP, AN, NN 을 metric network 로 계산하고 QuadrupletLossLayer 로 입력하는 방식으로 만들 수 있다.</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">build_model4</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,</span> <span class="n">network</span><span class="p">,</span> <span class="n">metricnetwork</span><span class="p">,</span><span class="n">margin</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">margin2</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
    <span class="sd">'''</span>
<span class="sd">    Define the Keras Model for training </span>
<span class="sd">        Input : </span>
<span class="sd">            input_shape : shape of input images</span>
<span class="sd">            network : Neural network to train outputing embeddings</span>
<span class="sd">            metricnetwork : Neural network to train the learned metric</span>
<span class="sd">            margin : minimal distance between Anchor-Positive and Anchor-Negative for the lossfunction (alpha1)</span>
<span class="sd">            margin2 : minimal distance between Anchor-Positive and Negative-Negative2 for the lossfunction (alpha2)</span>

<span class="sd">    '''</span>
     <span class="c1"># Define the tensors for the four input images</span>
    <span class="n">anchor_input</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">"anchor_input"</span><span class="p">)</span>
    <span class="n">positive_input</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">"positive_input"</span><span class="p">)</span>
    <span class="n">negative_input</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">"negative_input"</span><span class="p">)</span> 
    <span class="n">negative2_input</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">"negative2_input"</span><span class="p">)</span>
    <span class="c1"># Generate the encodings (feature vectors) for the four images</span>
    <span class="n">encoded_a</span> <span class="o">=</span> <span class="n">network</span><span class="p">(</span><span class="n">anchor_input</span><span class="p">)</span>
    <span class="n">encoded_p</span> <span class="o">=</span> <span class="n">network</span><span class="p">(</span><span class="n">positive_input</span><span class="p">)</span>
    <span class="n">encoded_n</span> <span class="o">=</span> <span class="n">network</span><span class="p">(</span><span class="n">negative_input</span><span class="p">)</span>
    <span class="n">encoded_n2</span> <span class="o">=</span> <span class="n">network</span><span class="p">(</span><span class="n">negative2_input</span><span class="p">)</span>
    <span class="c1">#compute the concatenated pairs</span>
    <span class="n">encoded_ap</span> <span class="o">=</span> <span class="n">Concatenate</span><span class="p">(</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s2">"Anchor-Positive"</span><span class="p">)([</span><span class="n">encoded_a</span><span class="p">,</span><span class="n">encoded_p</span><span class="p">])</span>
    <span class="n">encoded_an</span> <span class="o">=</span> <span class="n">Concatenate</span><span class="p">(</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s2">"Anchor-Negative"</span><span class="p">)([</span><span class="n">encoded_a</span><span class="p">,</span><span class="n">encoded_n</span><span class="p">])</span>
    <span class="n">encoded_nn</span> <span class="o">=</span> <span class="n">Concatenate</span><span class="p">(</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s2">"Negative-Negative2"</span><span class="p">)([</span><span class="n">encoded_n</span><span class="p">,</span><span class="n">encoded_n2</span><span class="p">])</span>
    <span class="c1">#compute the distances AP, AN, NN</span>
    <span class="n">ap_dist</span> <span class="o">=</span> <span class="n">metricnetwork</span><span class="p">(</span><span class="n">encoded_ap</span><span class="p">)</span>
    <span class="n">an_dist</span> <span class="o">=</span> <span class="n">metricnetwork</span><span class="p">(</span><span class="n">encoded_an</span><span class="p">)</span>
    <span class="n">nn_dist</span> <span class="o">=</span> <span class="n">metricnetwork</span><span class="p">(</span><span class="n">encoded_nn</span><span class="p">)</span>
    <span class="c1">#QuadrupletLoss Layer</span>
    <span class="n">loss_layer</span> <span class="o">=</span> <span class="n">QuadrupletLossLayer</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="n">margin</span><span class="p">,</span><span class="n">beta</span><span class="o">=</span><span class="n">margin2</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s1">'4xLoss'</span><span class="p">)([</span><span class="n">ap_dist</span><span class="p">,</span><span class="n">an_dist</span><span class="p">,</span><span class="n">nn_dist</span><span class="p">])</span>
    <span class="c1"># Connect the inputs with the outputs</span>
    <span class="n">network_train</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">anchor_input</span><span class="p">,</span><span class="n">positive_input</span><span class="p">,</span><span class="n">negative_input</span><span class="p">,</span><span class="n">negative2_input</span><span class="p">],</span><span class="n">outputs</span><span class="o">=</span><span class="n">loss_layer</span><span class="p">)</span>
    <span class="c1"># return the model</span>
    <span class="k">return</span> <span class="n">network_train</span>
</code></pre></div>
<p><img alt="" src="https://miro.medium.com/max/1313/1*1BZht07yu6SvnTkq4u1Bdg.png"/></p>
<h3 id="_2">실제 학습하기<a class="headerlink" href="#_2" title="Permanent link">¶</a></h3>
<p>(생략)</p>
<h3 id="discussion">Discussion<a class="headerlink" href="#discussion" title="Permanent link">¶</a></h3>
<p>실제로 학습해보니 4x 가 3x 에 비하여 논문에서 보여주는 뛰어난 성능이 나오지는 않았다. 그래서 우리는 좀 더 근본적인 이야기를 할 필요가 있어 보인다. 즉 정말로 두 시스템을 완벽하게 비교할 수 있는가? </p>
<ul>
<li>
<p>두 시스템의 하이퍼파라미터를 완벽히 동일하게 설정한다면, 4x 시스템의 성능이 떨어지는 것 같지 않은가?</p>
</li>
<li>
<p>mining strategy 가 생각보다 더 중요한 것 같지 않은가? 논문에서는 hardest 샘플을 가져왔지만, 우리는 로컬 배치에서의 hard 샘플을 가져왔다. 이게 국소적인 최적화를 낳은 것이 아닐까? </p>
</li>
<li>
<p>metric network 구조가 잘못되었을까? 계층 3 개를 두는 것이 충분해보였다. 계층을 더 두면 과적합이 일어날 것 같았다. 이 생각이 틀렸을까? </p>
</li>
<li>
<p>encoder 모델이 너무 단순해서 quadruplet loss 또는 learned metric 의 잠재성이 드러나지 않은 걸까? 논문에서 저자들은 우리가 사용한 모델보다 더 크고 복잡한 Resnet 을 사용했었다. </p>
</li>
<li>
<p>우리가 사용한 OMNIGLOT 데이터셋이 이 모델에 부적합한 게 아니었을까?</p>
</li>
<li>
<p>어쩌면 QuadrupletLoss 논문 자체가 <a href="https://deepai.org/publication/a-metric-learning-reality-check">A Metric Learning Reality Check</a> 에서처럼 기술적인 결함을 갖고 있던 게 아닐까? <a href="https://deepai.org/publication/a-metric-learning-reality-check">A Metric Learning Reality Check</a> 논문에서는 저자가 지난 몇년동안 Deep metric learning 이 과대평가되었다고 결론내린다. </p>
</li>
</ul>
<h3 id="summary">Summary<a class="headerlink" href="#summary" title="Permanent link">¶</a></h3>
<ul>
<li>
<p>learned metric 과 quadloss 는 상당히 흥미로운 아이디어이다. 하지만 나의 실험에서는 quadloss 의 효능을 보지 못했다. quadloss 는 아마 다른 상황에서 뛰어난 성능을 보이는 것 같다. </p>
</li>
<li>
<p>논문의 저자들은 4x 시스템이 일반적인 상황에서 더 낫다는 증명을 충분히 보이지 않았다. 이는 논문을 평가할 때 건전한 회의론을 갖는 것이 필요해 보인다.</p>
</li>
</ul>
<hr/>
<h2 id="beyond-triplet-loss-a-deep-quadruplet-network-for-person-re-identification">《Beyond triplet loss: a deep quadruplet network for person re-identification》<a class="headerlink" href="#beyond-triplet-loss-a-deep-quadruplet-network-for-person-re-identification" title="Permanent link">¶</a></h2>
<div class="admonition info">
<p class="admonition-title">Info</p>
<p>2017년 4월 6일에 나온 논문.</p>
</div>
<h2 id="abstract">Abstract<a class="headerlink" href="#abstract" title="Permanent link">¶</a></h2>
<p>우리는 triplet loss 보다 더 성능이 좋은 quadruplet loss 를 소개할 것이다. 4x 시스템은 margin-based online hard negative mining 을 사용한다.</p>
<h2 id="1-introduction">1. Introduction<a class="headerlink" href="#1-introduction" title="Permanent link">¶</a></h2>
<p>triplet loss 가 널리 사용되고 있지만, 사람의 재인식이라는 관점에서는 테스트 데이터셋에 사람의 신원이 보이지 않거나, 훈련 데이터셋과 겹치는 부분이 없기도 하다. triplet loss 는 큰 내부 클래스 변동에 대한 학습을 한다. 이것은 내부 클래스의 변동를 줄이고 외부 클래스 간의 변동를 높이면 에러율이 높아짐을 의미한다.</p>
<p>이에 따라 우리는 triplet loss 가 테스트 셋에서 보이는 성능을 높이기 위하여 내부 클래스 간 변동을 줄이고 외부 클래스 간의 변동을 높이는 연구를 했다. 그 연구 결과가 quadruplet ranking loss 이다. 이 시스템은 두 가지 기능을 한다. </p>
<ol>
<li>
<p>positive 들을 서로 가깝게 만든다. </p>
</li>
<li>
<p>negative 페어를 positive 페어로부터 밀어낸다.</p>
</li>
</ol>
<p>첫번째 기능은 triplet loss 에서 소개된 기능과 같다. 하지만 두번째 기능은 외부 클래스 간 변이를 줄이고 내부 클래스 간 변이를 최소화시키게 해준다.</p>
<p>이 두 기능의 밸런스는 2 개의 마진을 어떻게 설정하느냐에 따라 달라진다. 주의할점은 두번째 기능은 훈련 데이터셋에 대하여 모델이 좋은 성능을 내는데에 필요하지는 않다. 하지만 이 기능은 훈련 데이터셋과 테스트 데이터셋에 대한 일반적인 능력을 향상시키는데에 도움이 된다. 파트 5 에서 이 디자인 설계가 외부 클래스 간 변이를 높이고, 내부 클래스 간 변이를 줄이는 실험을 보여줄 것이다.</p>
<p>한편, 몇몇 사람 재인식 딥러닝 모델들은 학습을 위하여 binary classification loss 를 채택하기도 했다. 우리는 우리의 방법을 정당화하기 위하여 quadruplet loss, triplet loss, binary classification loss 를 이론적으로 비교해 볼 것이다.</p>
<p>또한 quadruplet loss 를 사용하는 quadruplet deep network 를 소개할 것이다. 이 모델은 입력으로 quadruplet 을 받게 된다. 실제 실험을 진행하게 되면 작은 데이터셋에 대해서도 이 시스템은 매우 많은 quadruplet sample 을 생성하게 되므로, 어떻게 적합한 샘플링을 할지가 중요한 문제이다. 우리는 샘플링 전략으로 margin-based online hard negative mining 을 택하여 모델을 학습하기 위해 hard sample 들을 추출하도록 했다. </p>
<p>우리는 알고리즘을 학습된 모델에 따라 적응적으로 margin threshold 를 설정하도록 만들었고, 이 margin threshold 가 hard 샘플들을 자동으로 선택하도록 만들었다. </p>
<p>정리하자면 우리는 다음 4 가지 성과를 냈다. </p>
<ol>
<li>
<p>strong push 와 weak push 전략을 사용하는 quadruplet loss</p>
</li>
<li>
<p>margin-based online hard negative mining 전략을 사용하는 quadruplet deep network 모델</p>
</li>
<li>
<p>통합된 관점에서 다른 손실들을 주는 이론적이고 통찰력있는 loss 관계 분석</p>
</li>
<li>
<p>대표적인 데이터셋(CUHK03, CUHK01, VIPeR)에 대한 뛰어난 성능(기존의 모델보다 더 뛰어난 성능)</p>
</li>
</ol>
<h2 id="2-related-work">2. Related work<a class="headerlink" href="#2-related-work" title="Permanent link">¶</a></h2>
<p>(생략)</p>
<h2 id="3-the-proposed-approachd">3. The proposed approachd<a class="headerlink" href="#3-the-proposed-approachd" title="Permanent link">¶</a></h2>
<h3 id="31-the-triplet-loss">3.1. The triplet loss<a class="headerlink" href="#31-the-triplet-loss" title="Permanent link">¶</a></h3>
<p>triplet loss 는 같은 사람 <span class="arithmatex">\(x_i, x_j\)</span> 와 다른 사람 <span class="arithmatex">\(x_k\)</span> 에 대한 triplet <span class="arithmatex">\(\{x_i, x_j, x_k\}\)</span> 들로 학습을 한다. triplet 시스템은 <span class="arithmatex">\(x_i\)</span> 를 <span class="arithmatex">\(x_k\)</span> 보다 <span class="arithmatex">\(x_j\)</span> 에 가깝게 만든다. 이는 <span class="arithmatex">\([z] _{+} = \max (z, 0)\)</span> 와 입력 이미지 <span class="arithmatex">\(f(x_i), f(x_j), f(x_k)\)</span> 와 하이퍼파라미터 <span class="arithmatex">\(\alpha _{trp}\)</span> 에 대하여</p>
<div class="arithmatex">\[ L _{trp} = \sum_{i,j,k}^{N} [\|f(x_i) - f(x_j)\| ^{2} _{2} - \|f(x_i) - f(x_k)\|^{2}_{2} + \alpha _{trp}]_{+} \tag{1} \]</div>
<p>으로 표현할 수 있다. image feature <span class="arithmatex">\(f\)</span> 는 학습이 진행되면서 정규화된다. threshold <span class="arithmatex">\(\alpha _{trp}\)</span> 는 positive 와 negative 에서 강제되는 여백이다. 또 triplet loss 는 얼굴 유사도를 표현하기 위하여 유클리드 거리를 채택했다.</p>
<p>하지만 우리는 유클리드 거리를 learned metric <span class="arithmatex">\(g(x_i, x_j)\)</span> 로 대체할 것이다. 이는 기존의 유클리드 거리에 비하여 여러 카메라 사진에 대한 훨씬 견고한 유사도 측정을 제공하게 된다. learned metric 에 의한 loss 함수는 다음과 같다.</p>
<div class="arithmatex">\[ L _{trp} = \sum_{i, j, k}^{N} [g(x_i, x_j) ^{2} - g(x_i, x_k) ^{2} + \alpha _{trp}]_{+} \tag{2} \]</div>
<p>방정식 <span class="arithmatex">\((1)\)</span> 에서 <span class="arithmatex">\(f(x_i)\)</span> 는 잘 정규화되고, <span class="arithmatex">\(\|f(x_i) - f(x_j)\| _{2} \in [0, 1]\)</span> 를 유지하게 된다. 하지만 방정식 <span class="arithmatex">\((2)\)</span> 의 <span class="arithmatex">\(g(x_i, x_j)\)</span> 는 벡터가 아니라 스칼라이다. 이에 따라 <span class="arithmatex">\(g(x_i, x_j)\)</span> 의 값이 폐구간 <span class="arithmatex">\([0, 1]\)</span> 을 유지할 없게 되고, 부분적으로 margin threshold <span class="arithmatex">\(\alpha _{trp}\)</span> 을 무효화시킨다. 가령 <span class="arithmatex">\(\alpha _{trp}\)</span> 이 아무리 커도 모델이 지속적으로 <span class="arithmatex">\(g(x_i, x_j)\)</span> 을 <span class="arithmatex">\(g(x_i, x_k)\)</span> 와 곱한다. 그래서 3.2 파트에서 triplet loss 를 업그레이드 한 quadruplet loss 를 소개한다.</p>
<h3 id="32-the-quadruplet-loss">3.2. The quadruplet loss<a class="headerlink" href="#32-the-quadruplet-loss" title="Permanent link">¶</a></h3>
<dl>
<dt><img alt="image" src="https://user-images.githubusercontent.com/16812446/96235604-f81c7f80-0fd5-11eb-88df-4644714296b4.png"/></dt>
<dd>
<p>Figure 2. 세 모딜의 서로 다른 loss 시스템. (a) 는 유클리드 거리를 사용하는 triplet loss 이다. (b) 는 learned metric 을 사용하는 triplet loss 이다. © 는 정규화가 포함된 우리가 향상시킨 triplet loss 이다.</p>
</dd>
</dl>
<p>먼저 Fig 2 (b) 를 뜻하는 정규화가 필요한 방정식 <span class="arithmatex">\((2)\)</span> 를 보완해보자. Fig 2 © 는 2 차원 출력을 갖는 fc 계층을 추가하여 정규화를 한 모습을 보여준다. <span class="arithmatex">\(g(x_i, x_j)\)</span> 의 값이 클수록 두 이미지가 유사하지 않다는 것을 뜻한다. 그러므로 fc 계층의 2 차원 중 하나가 두 이미지의 비유사도를 보여주어야 한다. 이때 2 차원 출력을 정규화하기 위하여 softmax 를 사용했다. 그러면 한 차원(Fig 2 © 의 빨간점)은 두 이미지의 비유사도를 표현하는데, loss 에 보내지고 학습이 될 <span class="arithmatex">\(g(x_i, x_j)\)</span> 의 역할을 한다. 그 결과 <span class="arithmatex">\(g(x_i, x_j)\)</span> 가 margin threshold <span class="arithmatex">\(\alpha _{trp}\)</span> 가 효과를 가지도록 폐구간 <span class="arithmatex">\([0, 1]\)</span> 로 정규화된다.</p>
<p>또 우리는 마지막 fc 계층 이후에 softmax 계층을 넣어서 두가지 출력이 유사도와 비유사도의 확률을 나타내도록 했다. 이것의 영향력을 파트 5.2 에서 Triplet(Improved w/o sfx) 와 Triplet(Improved) 와 비교해본다. </p>
<p>방정식 (2) 에서 triplet loss 가 positive 와 negative 사이의 거리를 기반으로 학습한다는 것을 알 수 있다. 우리의 quadruplet loss 는 새로운 제약을 추가했다. 이 제약은 negative 페어를 positive 페어로부터 멀리 민다. quadruplet loss 는 두 margin 을 뜻하는 <span class="arithmatex">\(\alpha _1, \alpha _2\)</span> 와 이미지 <span class="arithmatex">\(x_i\)</span> 의 신원 ID 를 뜻하는 <span class="arithmatex">\(s_i\)</span> 에 대하여 다음과 같다.</p>
<div class="arithmatex">\[ L _{quad} = \sum_{i,j,k}^{N} [g(x_i, x_j) ^{2} - g(x_i, x_k) ^{2} + \alpha _{1}] _{+} \\ + \sum_{i,j,k,l}^{N} [g(x_i, x_j) ^{2} - g(x_l, x_k) ^{2} + \alpha _{2}] _{+} \\ s_i = s_j, s_l \neq s_k, s_i \neq s_l, s_i \neq s_k \tag{3} \]</div>
<p>첫번째 항은 positive 와 negative 의 상대적 거리를 계산하는 방정식 (2) 와 같다. 두번째 항이 새롭게 추가되었는데, 이는 서로 다른 이미지에 대한 positive 와 negative 의 거리를 제약한다. 이 제약 덕분에 외부 클래스 간 최소 거리가 내부 클래스 간 최대 거리보다 커진다.</p>
<p>우리는 이 두 항이 손실에 미치는 영향력을 조정하기 위하여 두 margin threshold 를 도입했다. 이때 <span class="arithmatex">\(\alpha _1\)</span> 이 주된 제약(첫번째 항)을 이룰 수 있도록 충분히 커야 한다. 두번째 항의 <span class="arithmatex">\(\alpha _2\)</span> 는 두번째 항의 제약이 첫번째 항의 제약보다 약하도록 충분히 작아야 한다. 그러므로 우리의 시스템은 <span class="arithmatex">\(\alpha _1 &gt; \alpha _2\)</span> 가 되어야 한다.</p>
<dl>
<dt><img alt="image" src="https://user-images.githubusercontent.com/16812446/96238455-74649200-0fd9-11eb-9e10-25c0ee0ae7ad.png"/></dt>
<dd>
<p>Figure 3. quadruplet deep network. 빨간 그림자가 씌워진 부분이 Fig 2 © 에서 새롭게 추가된 제약이다.</p>
</dd>
</dl>
<p>위 그림에서 빨간 그림자를 제외하면 Fig 2 © 와 동일하다. 빨간 그림자가 새롭게 추가된 제약을 뜻한다. 이 제약을 통하여 triplet network 가 quadruplet network 로 된다. quadruplet network 는 positive 와 negative 만을 다루는 것(same probe images)이 아니라 different probe images 도 서로 멀어지게 한다. same probe 에 대해서는 positive 와 negative 에 strong push 를 하고, different probe 에 대해서는 상대적으로 약한 weaker push 를 하여 외부 클래스 간 변이를 줄인다.</p>
<h3 id="33-margin-based-online-hard-negative-mining">3.3. Margin-based online hard negative mining<a class="headerlink" href="#33-margin-based-online-hard-negative-mining" title="Permanent link">¶</a></h3>
<p>방정식 (1) 에서는 margin threshold 보다 짧은 거리를 갖는 샘플을 선택하는 online hard negative mining 을 사용했다. 하지만 이는 적합한 margin threshold 를 미리 정의하기에 어렵다. 작은 threshold 의 결과는 작은 hard samples 들이다. hard sample 들이 모델 학습에 기여하기 때문에, 작은 hard samples 들은 모델의 수렴을 느리게 만들고 모델이 차선의 해답을 내게 만든다. 반면 너무 큰 threshold 는 너무 많은 htard sample 들을 발생시켜서 과적합을 발생시킨다.</p>
<p>따라서 우리의 알고리즘은 학습된 모델에 대한 margin threshold 를 적응적으로 설정한다. 그리고 이렇게 설정된 threshold 로 hard sample 들을 샘플링한다. 적응적인 margin 의 메인 아이디어는 과대하게, 혹은 과소하게 hard smaple 들이 샘플링되는 것을 방지하는 것이다.</p>
<p>adaptive margin threshold 는 실질적으로 서로 다른 두 분포의 평균 거리를 표현하는데에 사용된다. 서로 다른 두 분포란 positive pair 의 거리 분포와 negative pair 거리 분포를 뜻한다. 이에 따라 우리는 서로다른 두 분포에 대한 거리의 평균을 적응적으로 설정하는 margin threshold 로 설정했다.</p>
<p>그러므로 adaptive margin threshold 는 두 거리 분포의 평균을 뜻하는 <span class="arithmatex">\(\mu _{p}, \mu _{n}\)</span> 과 positive pair 의 개수 <span class="arithmatex">\(N_p\)</span>, negative pair 의 개수 <span class="arithmatex">\(N_n\)</span> 과 상관 계수 <span class="arithmatex">\(w\)</span> 에 대하여 </p>
<div class="arithmatex">\[ \alpha = w(\mu _{n} - \mu _{p})\\ = w \bigg (\dfrac{1}{N_n} \sum_{i,k}^{N}g(x_i, x_k) ^{2} - \dfrac{1}{N_p}\sum_{i,j}^{N}g(x_i, x_j) ^{2}\bigg ) \\ s_i = s_j, s_i \neq s_k \tag{4} \]</div>
<p>이다. 우리는 방정식 (3) 의 <span class="arithmatex">\(\alpha _{1}\)</span> 에 대하여 <span class="arithmatex">\(w = 1\)</span> 로, <span class="arithmatex">\(\alpha _{2}\)</span> 에 대하여 <span class="arithmatex">\(w = 0.5\)</span> 로 설정했다.</p>
<p>실제로 구현할 때 두 거리 분포를 매 iteration 마다 구하는 것은 시간이 많이 걸린다. 따라서 각 배치마다의 두 분포의 평균을 대신 사용한다. 배치 크기를 <span class="arithmatex">\(M\)</span> 이라고 하면 <span class="arithmatex">\(N_p, N_n\)</span> 은 <span class="arithmatex">\(M, 2M\)</span> 으로 각각 설정된다. 최적화에는 SGD 를 사용했고, 우리의 손실 함수의 역전파 기울기 미분은</p>
<p><span class="arithmatex">\(\mu = \mu _n - \mu _p\)</span> 와 <span class="arithmatex">\(\iota[a] = \begin{cases} 1 &amp; a = \text{true}\\ 0 &amp; a = \text{false}\\ \end{cases}\)</span> 에 대하여 </p>
<div class="arithmatex">\[ \dfrac{\partial L _{quad}}{\partial g(x_i, x_j)} = \bigg (2 - \dfrac{2}{M} \bigg )g(x_i, x_j) \iota [g(x_i, x_k) ^{2} - g(x_i, x_j) ^{2} &lt; \max (\mu , 0)] + \\ \bigg (2 - \dfrac{1}{M} \bigg )g(x_i, x_j) \iota \bigg [g(x_i, x_k) ^{2} - g(x_i, x_j) ^{2} &lt; \dfrac{\max (\mu , 0)}{2} \bigg ] \\ \dfrac{\partial L _{quad}}{\partial g(x_i, x_k)} = \bigg (-2 + \dfrac{3}{2M} \bigg )g(x_i, x_j) \iota [g(x_i, x_k) ^{2} - g(x_i, x_j) ^{2} &lt; \max (\mu , 0)] \\ \dfrac{\partial L _{quad}}{\partial g(x_l, x_k)} = \bigg (-2 + \dfrac{3}{2M} \bigg )g(x_i, x_j) \iota \bigg [g(x_i, x_k) ^{2} - g(x_i, x_j) ^{2} &lt; \dfrac{\max (\mu , 0)}{2} \bigg ] \\ s_i = s_j, s_l \neq s_k , s_i \neq s_l, s_i \neq s_k \tag{5} \]</div>
<p>이다.</p>
<p>결과적으로 매 iteration 마다 margin 이 자동으로 두 거리 분포에 대하여 적응하게 된다. </p>
<h2 id="4-relationships-of-different-losses">4. Relationships of different losses<a class="headerlink" href="#4-relationships-of-different-losses" title="Permanent link">¶</a></h2>
<p>(생략)</p>
<p>Quadruplet vs Triplet: quadruplet 의 방정식의 두번째 항은 different probe images 에 대해서도 모델이 학습하게 하여 외부 클래스 간 변이를 높이고 테스트 데이터셋에 대한 성능을 높혀준다.</p>
<h2 id="5-experiment">5. Experiment<a class="headerlink" href="#5-experiment" title="Permanent link">¶</a></h2>
<dl>
<dt><img alt="image" src="https://user-images.githubusercontent.com/16812446/96247670-661c7300-0fe5-11eb-8344-62a849a2dd70.png"/></dt>
<dd>
<p>Figure 5. 데이터셋 CUHK03 의 훈련 데이터를 여러 모델로 학습한 후 내부 클래스와 외부 클래스 간 거리 분포 그래프이다. 빨간선이 내부 클래스 거리 분포, 파란선이 외부 클래스 거리 분포이다.</p>
</dd>
</dl>
<p>우리는 두 가지 실험을 진행하였다. </p>
<ol>
<li>
<p>다른 loss 와 성능을 비교해보기</p>
</li>
<li>
<p>현재 제안된 state-of-the-art 모델과 비교해보기</p>
</li>
</ol>
<h3 id="51-implementation-and-datasets">5.1. Implementation and Datasets<a class="headerlink" href="#51-implementation-and-datasets" title="Permanent link">¶</a></h3>
<p>우리는 Caffe 로 모델을 구현했고, 모든 이미지를 <span class="arithmatex">\(227 \times 227\)</span> 로 재조정한 다음 모델에 입력했다. 학습율은 <span class="arithmatex">\(10 ^{-3}\)</span> 으로, 배치 사이즈는 <span class="arithmatex">\(128\)</span> 로 설정했다. 모든 데이터셋에 대하여 이미지를 수평으로 복사하여 데이터셋 크기를 <span class="arithmatex">\(4\)</span> 배로 늘렸다.</p>
<p>margin-based hard negative mining 방식을 사용하지 않을 때는 margin threshold 를 각각 <span class="arithmatex">\(\alpha _1 = 1, \alpha _2 = 0.5\)</span> 로 설정했다. 왜냐하면 margin-based hard negative mining 이 막 시작될 때에는 두 거리 분포가 혼돈 상태라서 두 거리 분포의 평균이 무의미하기 때문이다. 그래서 처음 시작할 때 수렴을 가속화하기 위하여 미리 학습된 네트워크와 고정된 margin threshold 를 사용했다. ImageNet 에서 미리 학습된 AlexNet 모델로 처음 두 합성곱 계층의 커널 가중치를 초기화시켰다. </p>
<p><img alt="image" src="https://user-images.githubusercontent.com/16812446/96249267-eb088c00-0fe7-11eb-9fb3-515d34510710.png"/></p>
<h3 id="52-results-of-quadruplet-network">5.2. Results of Quadruplet Network<a class="headerlink" href="#52-results-of-quadruplet-network" title="Permanent link">¶</a></h3>
<p>Triplet 과 Quadruplet 시스템을 비교한 부분이 위 표의 아랫부분에 있다. MargOHNM 이 적응적인 margin threshold 방식을 사용한 것이다. 이게 성능이 제일 좋더라.</p>
<h3 id="53-comparison-with-the-state-of-the-arts">5.3. Comparison with the state of the arts<a class="headerlink" href="#53-comparison-with-the-state-of-the-arts" title="Permanent link">¶</a></h3>
<p>위 표의 상단부분에서 18 개의 다른 알고리즘과 비교해봤는데, 역시 우리게 제일 성능이 좋더라고 ㅋㅋ </p>
<h2 id="6-conclusion">6. Conclusion<a class="headerlink" href="#6-conclusion" title="Permanent link">¶</a></h2>
<p>하여튼 간에 margin-based online hard negative mining 을 샘플링 방식으로 사용하는 quadruplet loss 가 겁나 좋으니까 이거 써라 ㅇㅋ?</p>
</article>
</div>
</div>
<a class="md-top md-icon" data-md-component="top" data-md-state="hidden" href="#">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path></svg>
            Back to top
          </a>
</main>
<!-- 
<footer class="md-footer">
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        
      </div>
      
    </div>
  </div>
</footer> -->
</div>
<div class="md-dialog" data-md-component="dialog">
<div class="md-dialog__inner md-typeset"></div>
</div>
<script id="__config" type="application/json">{"base": "../..", "features": ["navigation.tabs", "navigation.top", "header.autohide"], "translations": {"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "search": "../../assets/javascripts/workers/search.409db549.min.js", "version": null}</script>
<script src="../../assets/javascripts/bundle.756773cc.min.js"></script>
<script src="../../javascripts/highlight.min.js"></script>
<script src="../../javascripts/config.js"></script>
<script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/auto-render.min.js"></script>
<script src="../../javascripts/b27b3e6448.js"></script>
</body>
</html>